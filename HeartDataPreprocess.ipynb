{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sb\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0   63    1   1     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1   67    1   4     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2   67    1   4     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3   37    1   3     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4   41    0   2     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  num  loc  \n",
       "0    3.0  0.0   6.0    0    0  \n",
       "1    2.0  3.0   3.0    2    0  \n",
       "2    2.0  2.0   7.0    1    0  \n",
       "3    3.0  0.0   3.0    0    0  \n",
       "4    1.0  0.0   3.0    0    0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing data from CSV\n",
    "all_df = pd.read_csv(\"HeartDiseaseData/HeartData.csv\",index_col = False, na_values = \"?\")\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute Data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"constant\").set_output(transform = \"pandas\")\n",
    "\n",
    "imputedData = imputer.fit_transform(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Onehot encoding catagorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "HotEncoder = OneHotEncoder(handle_unknown = \"ignore\",sparse_output = False)\n",
    "ColumnHeaders = [\"sex\",\"cp\",\"fbs\",\"restecg\",\"exang\",\"slope\",\"ca\",\"thal\",\"loc\"]\n",
    "\n",
    "hotDataSet = HotEncoder.fit_transform(imputedData[ColumnHeaders])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize data that isnt catagorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ColumnHeaders = [\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]\n",
    "\n",
    "#Xs is a normalised version of the required data\n",
    "Xs = scaler.fit_transform(imputedData[ColumnHeaders])\n",
    "\n",
    "#X is an unnormalised version of the data\n",
    "X = imputedData[ColumnHeaders]\n",
    "\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine HotData and normalised data. Convert to function if more is needed\n",
    "#normalisedHot_df = pd.merge(Xs,hotDataSet, left_index = True, right_index = True)\n",
    "normalisedHot_data = np.hstack((Xs,hotDataSet))\n",
    "\n",
    "\n",
    "#Combining hotData and unnormalised data\n",
    "#unnormalisedHot_df = pd.merge(imputedData[ColumnHeaders],hotDataSet, left_index = True, right_index = True)\n",
    "unnormalisedHot_data = np.hstack((X,hotDataSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making label for Y axis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "imputedData[\"num\"] = le.fit_transform(imputedData[\"num\"])\n",
    "y = imputedData[\"num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing Data into training and test sets \n",
    "\n",
    "#normalisedHot_df_train, normalisedHot_df_test, y_norm_train, y_norm_test = train_test_split(normalisedHot_data, y, test_size=0.3,random_state=1, stratify=y)\n",
    "#unnormalisedHot_df_train, unnormalisedHot_df_test, y_unnorm_train, y_unnorm_test = train_test_split(unnormalisedHot_data, y, test_size=0.3,random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    411\n",
       "1    196\n",
       "2    135\n",
       "3    135\n",
       "4     43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to access the variables\n",
    "\n",
    "- **normalisedHot_data** provides a normalised numpy array (Xs)\n",
    "- **unnormalisedHot_data** provides an unnormalised numpy array (X)\n",
    "- **y** provides the label (in this case it is num in the data set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
